<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1" /><title>关于kafka和logflume的小节</title><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@xiaotunza" /><meta name="twitter:title" content="关于kafka和logflume的小节" /><meta name="twitter:description" content="Kafka &amp; logflume"><meta name="description" content="Kafka &amp; logflume"><meta name="google-site-verification" content="epFgX0s_0RM3CdjwFcsewfXzPov2g8s9ZBOLyaIUH-o"><link rel="icon" href="/assets/favicon.png"><link rel="apple-touch-icon" href="/assets/touch-icon.png"><link rel="stylesheet" href="//code.cdn.mozilla.net/fonts/fira.css"><link rel="stylesheet" href="/assets/core.css"><link rel="canonical" href="/notes/kafka-logflume"><link rel="alternate" type="application/atom+xml" title="Gao Lei" href="/feed.xml" /></head><body><aside class="logo"> <a href="/"> <img src="http://www.gravatar.com/avatar/805e2bdf8d0b489403982fec64218277.png?s=80" class="gravatar"> </a> <span class="logo-prompt">Back to Home</span></aside><main> <noscript><style> article .footnotes { display: block; }</style></noscript><article><div class="center"><h1>关于kafka和logflume的小节</h1><time>June 2, 2015</time></div><div class="divider"></div><h1>Kafka &amp; logflume</h1><p>标签： kafka logflume MQ hadoop</p><hr><h2>Kafka</h2><ol><li>分布式的发布-订阅消息系统。</li><li>Apache顶级项目。</li><li>由Linkedin开发并在公司内部大规模使用（实时tracking，data bridge）。</li></ol><p>Kafka设计目标：</p><ul><li>Persistent messaging with O(1) disk structures that provide constant time performance even with many TB of stored messages.</li><li>High-throughput: even with very modest hardware Kafka can support hundreds of thousands of messages per second. --10w</li><li>Explicit support for partitioning messages over Kafka servers and distributing consumption over a cluster of consumer machines while maintaining per-partition ordering semantics.</li><li>Easily scale out.</li><li>Support for parallel data load into Hadoop.</li></ul><h3>Kafka组成</h3><p><img src="https://kafka.apache.org/images/producer_consumer.png" alt="Kafka WorkFlow"></p><ul><li>Broker<ul><li>topic<ul><li>partition</li></ul></li></ul></li><li>Producer<ul><li>Sync Producer</li><li>Async Producer<br></li></ul></li><li>Comsumer<ul><li>Comsumer Group</li></ul></li><li>Zookeeper (optional, external)</li></ul><p><img src="https://kafka.apache.org/images/consumer-groups.png" alt="Comsumer Group"></p><h3>Kafka的负载均衡</h3><p><img src="https://kafka.apache.org/images/log_anatomy.png" alt="Topics and Logs"></p><h3>消息队列工作模式选型</h3><p>|Pub-Sub|Pull|Push| |:-:|:---:|:---:| |负责主体|下游端|上游段| |实时性|取决于pull周期|较好| |上游状态|无|要保存push信息| |状态保存|分布式|集中式| |安全性|安全|不保证| |速度适应|根据consumer的消费能力来控制速度|由broker控制，很难适应消费速率不同的消费者|</p><p>对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 　　</p><hr><h3>扩展阅读</h3><p>关于Kafka的消息交付保障策略的介绍</p><blockquote><p><a href="https://kafka.apache.org/documentation.html#semantics">Kafka Delivery Guarantee</a></p></blockquote><p>push和pull的两篇介绍，通俗易懂</p><blockquote><p><a href="http://confusedofcalcutta.com/2007/12/27/thinking-about-push-and-pull-and-twitter-in-the-enterprise/">Thinking about Pubsh and Pull and Twitter in the Enterprise</a> <a href="http://www.cnblogs.com/sunli/archive/2010/08/24/twitter_feeds_push_pull.html">微博feed系统的推模式与拉模式和时间分区拉模式架构讨论</a></p></blockquote><p>Kafka为何能面对TB级别并发读写 <em>微微一笑，绝对不抽!</em></p><blockquote><p><a href="http://www.ibm.com/developerworks/cn/java/j-zerocopy/index.html">通过零拷贝实现有效数据传输</a> <a href="http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/index.html">Linux 中的零拷贝技术 part1</a> <a href="http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html">Linux 中的零拷贝技术 part2</a></p></blockquote><hr><h2>logflume</h2><h3>友盟数据平台收集日志的正确姿势</h3><h4>logflume的前世今生与未来</h4><h4>很久……很久以前………… <em>久到已经不好找现成的配图了</em></h4><ul><li>前端有N台nginx服务接log，把接收到的json log转给logtorrent再写成local text file</li><li>每小时rotate一次，并在本地gz压缩。Then scp到dp0，最终再写一个空的done文件</li><li>等N个done文件都齐全之后，degz-&gt;UALogParser-&gt;UALog(on HDFS)</li></ul><p>存在问题：</p><ul><li>单点compress与decompress，性能压力大</li><li>网络流量过于集中，每小时都会有单点性能问题</li><li>任务流水线长，优化空间大（前期准备工作1小时以上）</li><li>日志rotate切分不准，前后小时间会有log乱入！</li></ul><h4>The Ultimate savior--logflume</h4><p><img src="http://7tsz8v.com1.z0.glb.clouddn.com/LogAggregate.png" alt="日志收集"></p><h1>一揽子解决以上所有问题，完美~</h1><h2>（<em>此处有掌声</em>）</h2><h4>使用kafka之后的其他bonus</h4><ul><li>并发度过高，缓解压力</li><li>上下游解耦，异步通信</li><li>冗余，容错处理</li><li>顺序保证，灵活性</li><li>可扩展性，峰值处理能力</li></ul><h3>logflume---Mapreduce与kafka的纽带</h3><h4>看logflume如何对接两者以及在概念上的对应关系：</h4><p>|Kafka|Mapreduce| |:---:|:---:| |Topic|Log category| |Partition|Map(split)| |Producer|Map / Reducer| |Consumer Group|Job&#39;s map| |Consumer|Map| |Zookeeper(其中offset部分)|HDFS|</p><p><strong>On-disk format of a message</strong></p><p>|message length | 4 bytes (value: 1+4+n) | |-|-| |&quot;magic&quot; value | 1 byte| |crc | 4 bytes| |payload | n bytes|</p><h4>kafka的两种Java API</h4><ol><li>high level api</li><li>low！！！</li></ol><h4>logflume如何解决log乱入问题</h4><ol><li>kafka的message是无时间概念的（不标准，有很弱的按时间切分能力）</li><li>logflume双offset设计</li><li>可控的延迟机制</li></ol><h3>logflume的今天和明天</h3><ol><li>赋予logflume强大的流处理能力</li><li>增加流量控制功能 详见相关邮件和github的<a href="http://github.umeng.co/dp/iceberg/issues/670">issues 670</a></li><li>增加reduce来控制输出文件个数</li></ol><hr><h3>几次线上机器出现硬件问题的紧急修复分享</h3><ol><li>bla……</li><li>bla……</li><li>bla……</li></ol><hr><p>Q &amp; A:</p><ol><li><p>offset写入到zk中，每隔一段时间写一次， 这样很容易出现消费的offset没有及时写会zk，就导致一个消息多次消费，如何解决?</p><p>So effectively Kafka guarantees <strong><em>at-least-once</em></strong> delivery by default and allows the user to implement at most once delivery by disabling retries on the producer and <strong><em>committing its offset prior to processing a batch of messages</em></strong>. <strong><em>Exactly-once</em></strong> delivery requires co-operation with the destination storage system but Kafka provides the offset which makes implementing this straight-forward.</p></li><li><p>low level api 一般都怎么实现保存offset问题,因为这个是程序来控制offset更新,看过一些文章说把消费信息和offset放到hdfs中.</p></li><li><p>当kafka长时间没有进行consume操作,再次consume时，会稍微有些时间延迟, 这样问题 咱们有遇到么?</p></li><li><p>kafka控制台上一直报[2015-06-02 17:08:40,898] INFO Closing socket connection to /10.15.190.61. (kafka.network.Processor)类似这样的错误,貌似是一个已知的问题，问问怎么不让console显示这样的问题</p></li></ol></article><div class="back"> <a href="/">Back</a></div></main></body></html>